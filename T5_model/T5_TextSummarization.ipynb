{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe23b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5,6,7\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f972627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ae821e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ebb0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = \"./checkpoint/tokenizer\"\n",
    "tokenized_dataset_path = \"./checkpoint/tokenized_dataset\"\n",
    "\n",
    "if os.path.exists(tokenizer_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "    tokenizer.save_pretrained(tokenizer_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4986196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenized dataset from checkpoint...\n"
     ]
    }
   ],
   "source": [
    "prefix = \"summarize: \"\n",
    "\n",
    "def preprocess(example):\n",
    "    inputs = [prefix + doc for doc in example[\"article\"]]\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            example[\"highlights\"],\n",
    "            max_length=128,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=None\n",
    "        )\n",
    "\n",
    "    # Replace pad_token_id (typically 0) with -100 to ignore padding in loss\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(token if token != tokenizer.pad_token_id else -100) for token in label]\n",
    "        for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "if os.path.exists(tokenized_dataset_path):\n",
    "    print(\"Loading tokenized dataset from checkpoint...\")\n",
    "    tokenized_datasets = load_from_disk(tokenized_dataset_path)\n",
    "else:\n",
    "    print(\"Tokenizing dataset...\")\n",
    "    tokenized_datasets = raw_datasets.map(preprocess, batched=True, remove_columns=[\"article\", \"highlights\", \"id\"])\n",
    "    tokenized_datasets.save_to_disk(tokenized_dataset_path)\n",
    "\n",
    "# train_data = tokenized_datasets[\"train\"]\n",
    "# eval_data = tokenized_datasets[\"validation\"]\n",
    "train_data = tokenized_datasets[\"train\"]\n",
    "eval_data = tokenized_datasets[\"validation\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c18d79a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, EarlyStoppingCallback\n",
    "import evaluate\n",
    "\n",
    "def get_trainer(model, output_dir):\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        predict_with_generate=True,\n",
    "        num_train_epochs=5,\n",
    "        learning_rate=3e-5,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f'{output_dir}/logs',\n",
    "        logging_steps=10,\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"rougeL\",\n",
    "        generation_max_length=128,       # <-- set appropriate max length\n",
    "        generation_num_beams=4,  \n",
    "        report_to=\"none\",\n",
    "        local_rank=-1,  \n",
    "    )\n",
    "    rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from torch.nn.parallel import DataParallel\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        preds, labels = eval_pred\n",
    "\n",
    "        # Handle tuple output (common in Hugging Face models)\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "\n",
    "        # Ensure tensors are on CPU and handle multi-GPU gathering\n",
    "        if isinstance(preds, torch.Tensor):\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                # If using DataParallel, ensure proper gathering\n",
    "                preds = preds if preds.dim() > 0 else preds.unsqueeze(0)\n",
    "            preds = preds.cpu().numpy()\n",
    "        if isinstance(labels, torch.Tensor):\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                labels = labels if labels.dim() > 0 else labels.unsqueeze(0)\n",
    "            labels = labels.cpu().numpy()\n",
    "\n",
    "        # Convert to lists\n",
    "        preds = preds.tolist() if isinstance(preds, np.ndarray) else preds\n",
    "        labels = labels.tolist() if isinstance(labels, np.ndarray) else labels\n",
    "\n",
    "        # Debug: Inspect data before cleaning\n",
    "        print(\"Sample preds before cleaning:\", preds[:1])\n",
    "        print(\"Sample labels before cleaning:\", labels[:1])\n",
    "\n",
    "        # Clean predictions and labels: replace -100 with tokenizer.pad_token_id\n",
    "        # Ensure token IDs are within valid range\n",
    "        vocab_size = tokenizer.vocab_size\n",
    "        if tokenizer.pad_token_id is None:\n",
    "            tokenizer.pad_token_id = tokenizer.eos_token_id  # Fallback if pad_token_id is None\n",
    "        preds = [\n",
    "            [token if token != -100 else tokenizer.pad_token_id for token in seq]\n",
    "            for seq in preds\n",
    "        ]\n",
    "        labels = [\n",
    "            [token if token != -100 else tokenizer.pad_token_id for token in seq]\n",
    "            for seq in labels\n",
    "        ]\n",
    "\n",
    "        # Clamp token IDs to valid range [0, vocab_size - 1]\n",
    "        preds = [[int(min(max(token, 0), vocab_size - 1)) for token in seq] for seq in preds]\n",
    "        labels = [[int(min(max(token, 0), vocab_size - 1)) for token in seq] for seq in labels]\n",
    "\n",
    "        # Debug: Inspect cleaned data\n",
    "        print(\"Sample preds after cleaning:\", preds[:1])\n",
    "        print(\"Sample labels after cleaning:\", labels[:1])\n",
    "\n",
    "        try:\n",
    "            decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "            # Debug: Inspect decoded outputs\n",
    "            print(\"Sample decoded preds:\", decoded_preds[:1])\n",
    "            print(\"Sample decoded labels:\", decoded_labels[:1])\n",
    "        except Exception as e:\n",
    "            print(\"Decoding error:\", e)\n",
    "            print(\"Sample bad preds:\", preds[:1])\n",
    "            print(\"Sample bad labels:\", labels[:1])\n",
    "            return {\"rouge1\": 0.0, \"rouge2\": 0.0, \"rougeL\": 0.0}\n",
    "\n",
    "        # Compute ROUGE scores\n",
    "        result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "        \n",
    "        return {\n",
    "            \"rouge1\": round(result[\"rouge1\"], 4),\n",
    "            \"rouge2\": round(result[\"rouge2\"], 4),\n",
    "            \"rougeL\": round(result[\"rougeL\"], 4),\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=eval_data,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    "    )\n",
    "    return trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56b8b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-28 07:45:34,176] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: warning: librt.so.1, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: warning: libpthread.so.0, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: warning: libstdc++.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: warning: libm.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::runtime_error::~runtime_error()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__gxx_personality_v0@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::tellp()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::steady_clock::now()@GLIBCXX_3.4.19'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_replace_aux(unsigned long, unsigned long, unsigned long, char)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for bool@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_logic_error(char const*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::logic_error@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::~locale()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_end_catch@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::logic_error::~logic_error()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__si_class_type_info@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new[](unsigned long)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak_hard()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::basic_streambuf(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned short@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::resize(unsigned long, char)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char const*@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ctype<char>::_M_widen_init() const@GLIBCXX_3.4.11'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_invalid_argument(char const*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::operator=(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_free_exception@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::notify_one()@GLIBCXX_3.4.11'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::~Init()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_pure_virtual@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::flush()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__class_type_info@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_rethrow@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_fstream<char, std::char_traits<char> >::~basic_fstream()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::compare(char const*) const@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::system_clock::now()@GLIBCXX_3.4.19'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Hash_bytes(void const*, unsigned long, unsigned long)@CXXABI_1.3.5'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long long>(long long)@GLIBCXX_3.4.9'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char*@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_Prime_rehash_policy::_M_need_rehash(unsigned long, unsigned long, unsigned long) const@GLIBCXX_3.4.18'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::out_of_range@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long)@GLIBCXX_3.4.9'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::~ios_base()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::range_error::~range_error()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::~__basic_file()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_acquire@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<bool>(bool)@GLIBCXX_3.4.9'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::overflow_error@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::range_error@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_filebuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete[](void*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(unsigned long, char, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_transfer(std::__detail::_List_node_base*, std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::replace(unsigned long, unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::exception@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_M_destroy(std::allocator<wchar_t> const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream& std::istream::_M_extract<double>(double&)@GLIBCXX_3.4.9'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::basic_ifstream(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(std::string const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new(unsigned long)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::domain_error@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char, unsigned long) const@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::put(char)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for int@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_alloc()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_thread_atexit@CXXABI_1.3.7'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int*@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::~basic_ifstream()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::Init()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::condition_variable()@GLIBCXX_3.4.11'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::basic_filebuf()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::domain_error::~domain_error()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cerr@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::invalid_argument@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void*@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(std::string const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_rebalance_for_erase(std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_hook(std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_unhook()@GLIBCXX_3.4.15'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::_M_sync(char*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<char, std::char_traits<char> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `log2f@GLIBC_2.2.5'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::exception::~exception()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_create(unsigned long, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::is_open() const@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_istringstream()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::swap(std::string&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::basic_streambuf(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::init(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_cast()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::clear(std::_Ios_Iostate)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::operator=(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long*@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete(void*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(int)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_M_destroy(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<wchar_t, std::char_traits<wchar_t> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::runtime_error@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_insert_and_rebalance(bool, std::_Rb_tree_node_base*, std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_stringstream()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long>(long)@GLIBCXX_3.4.9'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::get()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long long@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::operator<< <std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::out_of_range::~out_of_range()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::length_error::~length_error()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::__ostream_insert<char, std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*, long)@GLIBCXX_3.4.9'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::invalid_argument::~invalid_argument()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::swap(std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cout@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long long>(unsigned long long)@GLIBCXX_3.4.9'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<void const*>(void const*)@GLIBCXX_3.4.9'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::underflow_error@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::out_of_range@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_allocate_exception@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void const*@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::init(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::reserve(unsigned long)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_begin_catch@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::open(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_M_sync(wchar_t*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::getline(char*, long, char)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istream<char, std::char_traits<char> >& std::getline<char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::basic_string<char, std::char_traits<char>, std::allocator<char> >&, char)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::~condition_variable()@GLIBCXX_3.4.11'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::insert(unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned char@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::ios_base()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_out_of_range(char const*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::overflow_error::~overflow_error()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_length_error(char const*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_system_error(int)@GLIBCXX_3.4.11'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ofstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<double>(double)@GLIBCXX_3.4.9'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::operator=(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long long@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(char const*, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_release@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_throw@CXXABI_1.3'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::underflow_error::~underflow_error()@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::length_error@GLIBCXX_3.4'\n",
      "/home/thaole/miniconda3/envs/hifed/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::~basic_filebuf()@GLIBCXX_3.4'\n",
      "collect2: error: ld returned 1 exit status\n",
      "/tmp/ipykernel_943/1518535546.py:104: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11220' max='11220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11220/11220 2:18:09, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.306000</td>\n",
       "      <td>2.343285</td>\n",
       "      <td>0.400900</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>0.279900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.236100</td>\n",
       "      <td>2.322655</td>\n",
       "      <td>0.409300</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.287600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.230300</td>\n",
       "      <td>2.316787</td>\n",
       "      <td>0.410500</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.288700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.172100</td>\n",
       "      <td>2.313570</td>\n",
       "      <td>0.410600</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.288600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.181200</td>\n",
       "      <td>2.312519</td>\n",
       "      <td>0.410600</td>\n",
       "      <td>0.189500</td>\n",
       "      <td>0.288600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 160, 1876, 47, 15574, 15, 26, 57, 331, 3026, 45, 18936, 18, 60, 3389, 4741, 14152, 3, 5, 8, 3741, 13, 27503, 19, 12, 36, 11972, 95, 9030, 1135, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 160, 1876, 47, 15574, 15, 26, 57, 331, 3026, 45, 18936, 18, 60, 3389, 4741, 14152, 3, 5, 8, 3741, 13, 27503, 19, 12, 36, 11972, 95, 9030, 1135, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . her gift was multiplied by data processing from donor-recipient pairs . the chain of surgeries is to be wrapped up friday .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 160, 23721, 3, 13804, 95, 28, 600, 331, 3, 5, 1296, 1221, 1204, 15127, 7, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 160, 23721, 3, 13804, 95, 28, 600, 331, 3, 5, 1296, 1221, 1204, 15127, 7, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . her generosity paired up with big data . six patients received transplants .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 160, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 20349, 7, 21, 66, 8, 380, 11, 14394, 976, 3, 9, 1670, 30, 3, 9, 13301, 543, 16, 160, 564, 608, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 160, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 20349, 7, 21, 66, 8, 380, 11, 14394, 976, 3, 9, 1670, 30, 3, 9, 13301, 543, 16, 160, 564, 608, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . her generosity paired up with big data, and six patients received transplants . \"thanks for all the support and prayers,\" a comment on a facebook page in her name read .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 160, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 20349, 7, 21, 66, 8, 380, 11, 14394, 976, 3, 9, 1670, 30, 3, 9, 13301, 543, 16, 160, 564, 608, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 160, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 20349, 7, 21, 66, 8, 380, 11, 14394, 976, 3, 9, 1670, 30, 3, 9, 13301, 543, 16, 160, 564, 608, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . her generosity paired up with big data, and six patients received transplants . \"thanks for all the support and prayers,\" a comment on a facebook page in her name read .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 160, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 20349, 7, 21, 66, 8, 380, 11, 14394, 976, 3, 9, 1670, 30, 3, 9, 13301, 543, 16, 160, 564, 608, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 160, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 20349, 7, 21, 66, 8, 380, 11, 14394, 976, 3, 9, 1670, 30, 3, 9, 13301, 543, 16, 160, 564, 608, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . her generosity paired up with big data, and six patients received transplants . \"thanks for all the support and prayers,\" a comment on a facebook page in her name read .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 12:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 160, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 20349, 7, 21, 66, 8, 380, 11, 14394, 976, 3, 9, 1670, 30, 3, 9, 13301, 543, 16, 160, 564, 608, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 160, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 20349, 7, 21, 66, 8, 380, 11, 14394, 976, 3, 9, 1670, 30, 3, 9, 13301, 543, 16, 160, 564, 608, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . her generosity paired up with big data, and six patients received transplants . \"thanks for all the support and prayers,\" a comment on a facebook page in her name read .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n",
      "Prompt Tuning Results: {'eval_loss': 2.316787004470825, 'eval_rouge1': 0.4105, 'eval_rouge2': 0.1895, 'eval_rougeL': 0.2887, 'eval_runtime': 807.8827, 'eval_samples_per_second': 16.547, 'eval_steps_per_second': 0.13, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# 1. Prompt Tuning\n",
    "from peft import PromptTuningConfig, get_peft_model, TaskType\n",
    "\n",
    "model_pt = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "model_pt.save_pretrained(\"./checkpoint/t5-prompt-base\")\n",
    "prompt_config = PromptTuningConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    num_virtual_tokens=20,\n",
    "    tokenizer_name_or_path=\"t5-base\"\n",
    ")\n",
    "model_pt = get_peft_model(model_pt, prompt_config)\n",
    "\n",
    "trainer_pt = get_trainer(model_pt, \"./checkpoint/t5-prompt-tuning\")\n",
    "trainer_pt.train()\n",
    "results_pt = trainer_pt.evaluate()\n",
    "print(\"Prompt Tuning Results:\", results_pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e7a038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_943/1518535546.py:104: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11220' max='11220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11220/11220 2:08:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.572800</td>\n",
       "      <td>1.548251</td>\n",
       "      <td>0.435400</td>\n",
       "      <td>0.209300</td>\n",
       "      <td>0.305200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.571700</td>\n",
       "      <td>1.539878</td>\n",
       "      <td>0.435500</td>\n",
       "      <td>0.209300</td>\n",
       "      <td>0.305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.533300</td>\n",
       "      <td>1.537020</td>\n",
       "      <td>0.435800</td>\n",
       "      <td>0.209800</td>\n",
       "      <td>0.305700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.524800</td>\n",
       "      <td>1.536475</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.209500</td>\n",
       "      <td>0.305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>1.536032</td>\n",
       "      <td>0.436200</td>\n",
       "      <td>0.209700</td>\n",
       "      <td>0.305500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 196, 214, 48, 1297, 2027, 19, 231, 4038, 145, 66, 13, 178, 976, 255, 845, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 196, 214, 48, 1297, 2027, 19, 231, 4038, 145, 66, 13, 178, 976, 255, 845, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . Her generosity paired up with big data, and six patients received transplants . \"I know this entire journey is much bigger than all of us,\" she says .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 196, 214, 48, 1297, 2027, 19, 231, 4038, 145, 66, 13, 178, 976, 255, 845, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 196, 214, 48, 1297, 2027, 19, 231, 4038, 145, 66, 13, 178, 976, 255, 845, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . Her generosity paired up with big data, and six patients received transplants . \"I know this entire journey is much bigger than all of us,\" she says .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 196, 214, 48, 1297, 2027, 19, 231, 4038, 145, 66, 13, 178, 976, 255, 845, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 196, 214, 48, 1297, 2027, 19, 231, 4038, 145, 66, 13, 178, 976, 255, 845, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . Her generosity paired up with big data, and six patients received transplants . \"I know this entire journey is much bigger than all of us,\" she says .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 196, 214, 48, 1297, 2027, 19, 231, 4038, 145, 66, 13, 178, 976, 255, 845, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 196, 214, 48, 1297, 2027, 19, 231, 4038, 145, 66, 13, 178, 976, 255, 845, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . Her generosity paired up with big data, and six patients received transplants . \"I know this entire journey is much bigger than all of us,\" she says .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 196, 214, 48, 1297, 2027, 19, 231, 4038, 145, 66, 13, 178, 976, 255, 845, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 196, 214, 48, 1297, 2027, 19, 231, 4038, 145, 66, 13, 178, 976, 255, 845, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . Her generosity paired up with big data, and six patients received transplants . \"I know this entire journey is much bigger than all of us,\" she says .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 13:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 196, 214, 48, 1297, 2027, 19, 231, 4038, 145, 66, 13, 178, 976, 255, 845, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 6, 11, 1296, 1221, 1204, 15127, 7, 3, 5, 96, 196, 214, 48, 1297, 2027, 19, 231, 4038, 145, 66, 13, 178, 976, 255, 845, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . Her generosity paired up with big data, and six patients received transplants . \"I know this entire journey is much bigger than all of us,\" she says .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n",
      "Layer Freezing Results: {'eval_loss': 1.537019968032837, 'eval_rouge1': 0.4358, 'eval_rouge2': 0.2098, 'eval_rougeL': 0.3057, 'eval_runtime': 867.909, 'eval_samples_per_second': 15.403, 'eval_steps_per_second': 0.121, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# 2. Layer Freezing (freeze encoder)\n",
    "model_lf = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "model_lf.save_pretrained(\"./checkpoint/t5-layer-base\")\n",
    "for param in model_lf.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "trainer_lf = get_trainer(model_lf, \"./checkpoint/t5-layer-freeze\")\n",
    "trainer_lf.train()\n",
    "results_lf = trainer_lf.evaluate()\n",
    "print(\"Layer Freezing Results:\", results_lf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5177fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_943/1518535546.py:104: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11220' max='11220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11220/11220 2:34:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.604600</td>\n",
       "      <td>1.577658</td>\n",
       "      <td>0.434200</td>\n",
       "      <td>0.207800</td>\n",
       "      <td>0.303600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.608500</td>\n",
       "      <td>1.569851</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.304600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.565900</td>\n",
       "      <td>1.566509</td>\n",
       "      <td>0.435400</td>\n",
       "      <td>0.208900</td>\n",
       "      <td>0.304800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.566800</td>\n",
       "      <td>1.565153</td>\n",
       "      <td>0.435500</td>\n",
       "      <td>0.208900</td>\n",
       "      <td>0.304600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.572100</td>\n",
       "      <td>1.565161</td>\n",
       "      <td>0.435100</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.304500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 3, 5, 7643, 1221, 33, 4281, 15127, 7, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 3, 5, 7643, 1221, 33, 4281, 15127, 7, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . Her generosity paired up with big data . Six patients are receiving transplants .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 3, 5, 7643, 1221, 33, 4281, 15127, 7, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 3, 5, 7643, 1221, 33, 4281, 15127, 7, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . Her generosity paired up with big data . Six patients are receiving transplants .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 3, 5, 7643, 1221, 33, 4281, 15127, 7, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 3, 5, 7643, 1221, 33, 4281, 15127, 7, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . Her generosity paired up with big data . Six patients are receiving transplants .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 47, 15574, 15, 26, 57, 600, 331, 3, 5, 7643, 1221, 33, 4281, 15127, 7, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 47, 15574, 15, 26, 57, 600, 331, 3, 5, 7643, 1221, 33, 4281, 15127, 7, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . Her generosity was multiplied by big data . Six patients are receiving transplants .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 47, 15574, 15, 26, 57, 600, 331, 3, 5, 7643, 1221, 33, 4281, 15127, 7, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 47, 15574, 15, 26, 57, 600, 331, 3, 5, 7643, 1221, 33, 4281, 15127, 7, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . Her generosity was multiplied by big data . Six patients are receiving transplants .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 14:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample preds before cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 3, 5, 7643, 1221, 33, 4281, 15127, 7, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample labels before cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]]\n",
      "Sample preds after cleaning: [[0, 1811, 6073, 4027, 302, 7, 986, 1891, 80, 13, 160, 11546, 7, 12, 3, 9, 13037, 3, 5, 1347, 23721, 3, 13804, 95, 28, 600, 331, 3, 5, 7643, 1221, 33, 4281, 15127, 7, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample labels after cleaning: [[1811, 6073, 4027, 302, 7, 986, 1500, 12, 428, 3, 9, 11546, 12, 3, 9, 13037, 3, 5, 71, 126, 1218, 478, 2139, 160, 9294, 18421, 15127, 7, 21, 1296, 11546, 1221, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Sample decoded preds: ['Zully Broussard gave one of her kidneys to a stranger . Her generosity paired up with big data . Six patients are receiving transplants .']\n",
      "Sample decoded labels: ['Zully Broussard decided to give a kidney to a stranger . A new computer program helped her donation spur transplants for six kidney patients .']\n",
      "LoRA Results: {'eval_loss': 1.5665086507797241, 'eval_rouge1': 0.4354, 'eval_rouge2': 0.2089, 'eval_rougeL': 0.3048, 'eval_runtime': 891.608, 'eval_samples_per_second': 14.993, 'eval_steps_per_second': 0.118, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# 3. LoRA Fine-tuning\n",
    "from peft import LoraConfig\n",
    "\n",
    "model_lora = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "model_lora.save_pretrained(\"./checkpoint/t5-lora-base\")\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "model_lora = get_peft_model(model_lora, lora_config)\n",
    "\n",
    "trainer_lora = get_trainer(model_lora, \"./checkpoint/t5-lora\")\n",
    "trainer_lora.train()\n",
    "results_lora = trainer_lora.evaluate()\n",
    "print(\"LoRA Results:\", results_lora)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d165f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /home/thaole/miniconda3/envs/hifed/lib/python3.10/site-packages (0.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07dad38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method            ROUGE-1    ROUGE-2    ROUGE-L\n",
      "--------------  ---------  ---------  ---------\n",
      "Prompt Tuning      0.4105     0.1895     0.2887\n",
      "Layer Freezing     0.4358     0.2098     0.3057\n",
      "LoRA               0.4354     0.2089     0.3048\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate([\n",
    "    [\"Prompt Tuning\", results_pt['eval_rouge1'], results_pt['eval_rouge2'], results_pt['eval_rougeL']],\n",
    "    [\"Layer Freezing\", results_lf['eval_rouge1'], results_lf['eval_rouge2'], results_lf['eval_rougeL']],\n",
    "    [\"LoRA\", results_lora['eval_rouge1'], results_lora['eval_rouge2'], results_lora['eval_rougeL']]\n",
    "], headers=[\"Method\", \"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "194f2e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Your max_length is set to 128, but your input_length is only 67. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=33)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Article: \n",
      "NASA's Perseverance rover has successfully collected samples from Mars that may contain signs of ancient microbial life. Scientists are now preparing to bring the samples back to Earth for further analysis, hoping to answer the age-old question of whether life ever existed on the red planet.\n",
      "\n",
      "\n",
      "Example Summary:\n",
      " NASA's Perseverance rover has successfully collected samples from Mars . Scientists are now preparing to bring the samples back to Earth for further analysis .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=model_lora, tokenizer=tokenizer)\n",
    "article = \"\"\"\n",
    "NASA's Perseverance rover has successfully collected samples from Mars that may contain signs of ancient microbial life. Scientists are now preparing to bring the samples back to Earth for further analysis, hoping to answer the age-old question of whether life ever existed on the red planet.\n",
    "\"\"\"\n",
    "summary = summarizer(\"summarize: \" + article, max_length=128, min_length=30, do_sample=False)\n",
    "print(\"\\nExample Article:\", article)\n",
    "print(\"\\nExample Summary:\\n\", summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154bebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hifed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
