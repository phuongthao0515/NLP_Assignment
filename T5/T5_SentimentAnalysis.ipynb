{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1988069d",
   "metadata": {},
   "source": [
    "### T5 MODEL - TASK: SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be09ef8",
   "metadata": {},
   "source": [
    "### 🛠️ SETUP\n",
    "\n",
    "#### Dataset: IMDB\n",
    "- The IMDB dataset consists of movie reviews labeled as either **positive** or **negative**, commonly used for **sentiment classification** tasks.\n",
    "- It contains 50,000 reviews, evenly split into training and testing sets.\n",
    "\n",
    "#### Model: T5-small\n",
    "- `t5-small` is a lightweight version of the **Text-to-Text Transfer Transformer (T5)** developed by Google.\n",
    "- T5 treats every NLP task as a **text-to-text problem**, meaning both input and output are formatted as text.\n",
    "- In this experiment, the model is fine-tuned to perform **sentiment classification** by mapping a review text to its corresponding label (\"positive\" or \"negative\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79212f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4,5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.system(\"your_command_here 2>/dev/null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865ffddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer,Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, Seq2SeqTrainer\n",
    "from datasets import load_dataset\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import evaluate\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c064e5bd",
   "metadata": {},
   "source": [
    "### MODEL AND DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and dataset\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7299e4",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d82f9bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [\"sentiment: \" + str(text) if text else \"sentiment: \" for text in examples[\"text\"]]\n",
    "    targets = [\"positive\" if label == 1 else \"negative\" for label in examples[\"label\"]]\n",
    "\n",
    "    # Tokenize input\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, max_length=512, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    # Tokenize labels \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets, max_length=10, truncation=True, padding=\"max_length\"\n",
    "        )\n",
    "\n",
    "    labels_ids = labels[\"input_ids\"]\n",
    "\n",
    "    # Change pad token id to -100\n",
    "    labels_ids = [\n",
    "        [(token_id if token_id != tokenizer.pad_token_id else -100) for token_id in label]\n",
    "        for label in labels_ids\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels_ids\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "eval_dataset = tokenized_datasets[\"test\"]\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "eval_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e2ba0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0].keys())\n",
    "print(eval_dataset[0].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e359d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds_ids, labels = eval_preds  # preds_ids = generated token IDs\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds_ids, skip_special_tokens=True)\n",
    "    labels_for_decode = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
    "    decoded_labels = tokenizer.batch_decode(labels_for_decode, skip_special_tokens=True)\n",
    "\n",
    "    label_map = {\"positive\": 1, \"negative\": 0}\n",
    "    \n",
    "    decoded_preds = [p.lower().strip() for p in decoded_preds]\n",
    "    decoded_labels = [l.lower().strip() for l in decoded_labels]\n",
    "\n",
    "    valid_data = [\n",
    "        (label_map[p], label_map[l])\n",
    "        for p, l in zip(decoded_preds, decoded_labels)\n",
    "        if p in label_map and l in label_map\n",
    "    ]\n",
    "\n",
    "    if not valid_data:\n",
    "        return {\"accuracy\": 0.0}\n",
    "\n",
    "    pred_labels, true_labels = zip(*valid_data)\n",
    "    return metric.compute(predictions=pred_labels, references=true_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd39675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam search generate function for eval\n",
    "def generate_with_beam_search(model, inputs, num_beams=5, max_length=10):\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        num_beams=num_beams,\n",
    "        max_length=max_length,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return outputs\n",
    "\n",
    "# Custom Trainer to use beam search during evaluation\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "class BeamSearchTrainer(Seq2SeqTrainer):\n",
    "    def __init__(self, *args, custom_tokenizer=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._custom_tokenizer = custom_tokenizer \n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only=False, ignore_keys=None):\n",
    "        # unwrap DataParallel \n",
    "        model_to_use = model.module if hasattr(model, \"module\") else model\n",
    "\n",
    "        has_labels = \"labels\" in inputs\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = model_to_use.generate(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs.get(\"attention_mask\", None),\n",
    "                num_beams=5,\n",
    "                max_length=10,\n",
    "                early_stopping=True,\n",
    "                return_dict_in_generate=True,\n",
    "                output_scores=False\n",
    "            ).sequences\n",
    "\n",
    "            # compute loss\n",
    "            loss = model_to_use(**inputs).loss if has_labels else None\n",
    "\n",
    "        # Pad nếu cần\n",
    "        pad_token_id = getattr(self._custom_tokenizer, \"pad_token_id\", 0)\n",
    "        if generated_tokens.shape[-1] < 10:\n",
    "            generated_tokens = torch.nn.functional.pad(\n",
    "                generated_tokens, (0, 10 - generated_tokens.shape[-1]), value=pad_token_id\n",
    "            )\n",
    "\n",
    "        labels = inputs[\"labels\"] if has_labels else None\n",
    "        return (loss, generated_tokens, labels)\n",
    "\n",
    "\n",
    "# Training arguments template\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "def get_training_args(output_dir):\n",
    "    return Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"epoch\",     # Evaluate once per epoch\n",
    "        save_strategy=\"epoch\",           # Save once per epoch\n",
    "        logging_strategy=\"epoch\",        # Log once per epoch\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=10,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        greater_is_better=True,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        report_to=\"none\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8b057",
   "metadata": {},
   "source": [
    "#### LORA FINE-TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35ac7f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3910' max='3910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3910/3910 38:19, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.682800</td>\n",
       "      <td>0.153016</td>\n",
       "      <td>0.873795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.143606</td>\n",
       "      <td>0.884160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.161500</td>\n",
       "      <td>0.134185</td>\n",
       "      <td>0.891480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.153600</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.896120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>0.128708</td>\n",
       "      <td>0.896960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.125620</td>\n",
       "      <td>0.898960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.144400</td>\n",
       "      <td>0.124914</td>\n",
       "      <td>0.900520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>0.123136</td>\n",
       "      <td>0.902560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>0.123292</td>\n",
       "      <td>0.902000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.140400</td>\n",
       "      <td>0.123021</td>\n",
       "      <td>0.902520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='391' max='391' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [391/391 01:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12313584238290787, 'eval_accuracy': 0.90256, 'eval_runtime': 132.2732, 'eval_samples_per_second': 189.003, 'eval_steps_per_second': 2.956, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# ------------- LoRA Fine-tuning -------------\n",
    "print(\"LoRA Fine-tuning\")\n",
    "\n",
    "base_model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Instantiate data collator with your tokenizer and model (for label padding)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=base_model)\n",
    "\n",
    "# Freeze base model\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# LoRA config \n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q\", \"v\"], \n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "training_args = get_training_args(\"t5-imdb-lora\")\n",
    "\n",
    "trainer = BeamSearchTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,   \n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    custom_tokenizer=tokenizer  # Pass the tokenizer for beam search\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"Evaluation:\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74d4556e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA Fine-tuning result:  {'eval_loss': 0.12313584238290787, 'eval_accuracy': 0.90256, 'eval_runtime': 132.2732, 'eval_samples_per_second': 189.003, 'eval_steps_per_second': 2.956, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"LoRA Fine-tuning result: \", eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc0b1d",
   "metadata": {},
   "source": [
    "#### STANDARD FINE-TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb10e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Standard Fine-tuning ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3910' max='3910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3910/3910 36:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.305300</td>\n",
       "      <td>0.116356</td>\n",
       "      <td>0.912680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>0.116875</td>\n",
       "      <td>0.912880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.110600</td>\n",
       "      <td>0.101123</td>\n",
       "      <td>0.924400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.925280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.101324</td>\n",
       "      <td>0.927040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.097965</td>\n",
       "      <td>0.928160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>0.099598</td>\n",
       "      <td>0.929080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.084800</td>\n",
       "      <td>0.099813</td>\n",
       "      <td>0.928600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.100888</td>\n",
       "      <td>0.929440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.100160</td>\n",
       "      <td>0.928720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='391' max='391' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [391/391 01:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard fine-tuning results: {'eval_loss': 0.10088798403739929, 'eval_accuracy': 0.92944, 'eval_runtime': 126.9253, 'eval_samples_per_second': 196.966, 'eval_steps_per_second': 3.081, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# STANDARD FINE-TUNING\n",
    "\n",
    "print(\"=== Standard Fine-tuning ===\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "training_args = get_training_args(\"t5-imdb-standard\")  # Should return Seq2SeqTrainingArguments\n",
    "\n",
    "trainer = BeamSearchTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    custom_tokenizer=tokenizer,  # Pass the tokenizer for beam search\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Evaluation after training\n",
    "results_standard = trainer.evaluate()\n",
    "\n",
    "# print(\"Standard fine-tuning accuracy:\", results_standard.get(\"eval_accuracy\", \"Metric not available\"))\n",
    "print(\"Standard fine-tuning results:\", results_standard)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2b1e02",
   "metadata": {},
   "source": [
    "#### FREEZE FINE-TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b694acab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze Fine-tuning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3910' max='3910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3910/3910 33:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.895600</td>\n",
       "      <td>0.132170</td>\n",
       "      <td>0.891396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.121123</td>\n",
       "      <td>0.903240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.138800</td>\n",
       "      <td>0.115645</td>\n",
       "      <td>0.907396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.134700</td>\n",
       "      <td>0.113589</td>\n",
       "      <td>0.908636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.111689</td>\n",
       "      <td>0.911076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.129300</td>\n",
       "      <td>0.110224</td>\n",
       "      <td>0.911673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.109630</td>\n",
       "      <td>0.913157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.124900</td>\n",
       "      <td>0.110075</td>\n",
       "      <td>0.912953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.123700</td>\n",
       "      <td>0.108858</td>\n",
       "      <td>0.914433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.123800</td>\n",
       "      <td>0.108736</td>\n",
       "      <td>0.914513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='391' max='391' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [391/391 02:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze fine-tuning results: {'eval_loss': 0.10873585939407349, 'eval_accuracy': 0.9145131610528843, 'eval_runtime': 142.3442, 'eval_samples_per_second': 175.631, 'eval_steps_per_second': 2.747, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# ------------- Freeze Fine-tuning -------------\n",
    "print(\"Freeze Fine-tuning\")\n",
    "\n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "# Load base model\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Freeze encoder\n",
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Freeze shared embedding\n",
    "for param in model.shared.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Setup training arguments\n",
    "training_args = get_training_args(\"t5-imdb-freeze\")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = BeamSearchTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "    custom_tokenizer=tokenizer,  # Pass the tokenizer for beam search\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Evaluation:\")\n",
    "freeze_results = trainer.evaluate()\n",
    "print(\"Freeze fine-tuning results:\", freeze_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c700cd",
   "metadata": {},
   "source": [
    "#### SUMMARY TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ab4ea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Fine-tune Method   |   Eval Loss |   Eval Accuracy |\n",
      "|--------------------|-------------|-----------------|\n",
      "| Standard           |      0.1009 |          0.9294 |\n",
      "| Freeze             |      0.1087 |          0.9145 |\n",
      "| LoRA               |      0.1231 |          0.9026 |\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Create a table 3 fine-tune techniques\n",
    "results_table = [\n",
    "    [\"Standard\", round(results_standard[\"eval_loss\"], 4), round(results_standard[\"eval_accuracy\"], 4)],\n",
    "    [\"Freeze\", round(freeze_results[\"eval_loss\"], 4), round(freeze_results[\"eval_accuracy\"], 4)],\n",
    "    [\"LoRA\", round(eval_results[\"eval_loss\"], 4), round(eval_results[\"eval_accuracy\"], 4)],\n",
    "]\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(results_table, headers=[\"Fine-tune Method\", \"Eval Loss\", \"Eval Accuracy\"], tablefmt=\"github\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f18aeea",
   "metadata": {},
   "source": [
    "#### CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1ef916",
   "metadata": {},
   "source": [
    "1. **Standard Fine-tuning** (Accuracy: **92.94%**, Loss: **0.1009**):\n",
    "   - Achieves the **lowest eval loss** and **highest accuracy**.\n",
    "   - Indicates that full fine-tuning unlocks the best model performance.\n",
    "   - However, it is also the **most resource-intensive** (memory, GPU, training time).\n",
    "\n",
    "2. **Freeze** (Accuracy: **91.45%**, Loss: **0.1087**):\n",
    "   - Slightly worse performance than Standard.\n",
    "   - A good trade-off between **efficiency** and **accuracy**.\n",
    "   - Recommended when resources are limited or to avoid overfitting.\n",
    "\n",
    "3. **LoRA (Low-Rank Adaptation)** (Accuracy: **90.26%**, Loss: **0.1231**):\n",
    "   - Produces the **highest loss** and **lowest accuracy**.\n",
    "   - Useful in **parameter-efficient** fine-tuning scenarios.\n",
    "   - Acceptable choice for **scalability** or **low-resource environments**.\n",
    "\n",
    "---\n",
    "- **Standard**: Best performance (92.94% accuracy, 0.1009 loss), highest cost.\n",
    "- **Freeze**: Balanced trade-off (91.45% accuracy, 0.1087 loss).\n",
    "- **LoRA**: Efficient but slightly lower performance (90.26% accuracy, 0.1231 loss).\n",
    "\n",
    "> **Summary**: For sentiment analysis on the IMDB dataset using `t5-small`, full fine-tuning (Standard) remains the most effective method in terms of evaluation performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hifed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
